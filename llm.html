<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>UTS</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <nav class="topnav">
        <a href="home.html">Home</a>
        <a href="generative.html">AI Generative</a>
        <a href="llm.html">Large Language Model (LLM)</a>
        <a href="agi.html">Artificial General Intelligence (AGI)</a>
        <a href="contact.html">Contact</a>
    </nav>
    <nav class="content">
        <table>
            <tr>
                <td>
                    <h1>WELCOME TO MY ARTIFICIAL INTELLIGENCE</h1>
                </td>
            </tr>
        </table>
    </nav>
    <main>
        <section id="what-is-ai">
            <h1>Large Language Model (LLM)</h1>
            <h2>Apa itu Model Bahasa Besar ?</h2>
            <p>Model bahasa besar, juga dikenal sebagai LLM, adalah model deep learning yang sangat besar yang dilatih sebelumnya pada sejumlah besar data. Transformator yang mendasari adalah rangkaian jaringan neural yang terdiri dari enkoder dan dekoder dengan kemampuan perhatian mandiri. Enkoder dan dekoder mengekstraksi makna dari urutan teks dan memahami hubungan antara kata dan frasa di dalamnya.</p>
            <p>LLM Transformator mampu melakukan pelatihan tanpa pengawasan meski penjelasan yang lebih tepat adalah bahwa transformator melakukan pembelajaran mandiri. Melalui proses inilah transformator belajar memahami tata bahasa, bahasa, dan pengetahuan dasar.</p>
            <p>Tidak seperti jaringan neural berulang (RNN) sebelumnya yang secara berurutan memproses input, transformator memproses seluruh urutan secara paralel. Hal ini memungkinkan para ilmuwan data untuk menggunakan GPU guna melatih LLM berbasis transformator sehingga secara signifikan mengurangi waktu pelatihan.</p>
            <!-- <h3>Untuk detailnya bisa buka URL di bawah ini</h3> -->
        </section>
    </main>
    <main>
        <section id="what-is-ai">
            <h2>Mengapa model bahasa besar itu penting?</h2>
            <p>Model bahasa besar sangat fleksibel. Satu model dapat melakukan tugas yang sama sekali berbeda, seperti menjawab pertanyaan, meringkas dokumen, menerjemahkan bahasa, dan melengkapi kalimat. LLM memiliki potensi untuk mengganggu pembuatan konten serta cara orang menggunakan mesin pencari dan asisten virtual.</p>
            <p>Meski tidak sempurna, LLM menunjukkan kemampuan luar biasa untuk membuat prediksi berdasarkan jumlah prompt atau input yang relatif kecil. LLM dapat digunakan untuk AI generatif (kecerdasan buatan) untuk menghasilkan konten berdasarkan perintah input dalam bahasa manusia.</p>
            <h3>Berikut Beberapa Contoh LLM</h3>
            <ul>
                <li>Model GPT-3 milik Open AI memiliki 175 miliar parameter. Model yang setara, ChatGPT, dapat mengidentifikasi pola dari data dan menghasilkan output alami yang mudah dibaca. Meski kita tidak tahu ukuran Claude 2, model ini dapat mengambil input hingga 100 ribu token di setiap prompt, yang berarti dapat bekerja dengan lebih dari ratusan halaman dokumentasi teknis atau bahkan seluruh buku.</li>
                <li>Model Jurassic-1 milik AI21 Labs memiliki 178 miliar parameter dan kosakata token sebanyak 250.000 bagian kata dan kemampuan percakapan serupa.</li>
                <li>Model Command milik Cohere memiliki kemampuan serupa dan dapat bekerja di lebih dari 100 bahasa yang berbeda.</li>
                <li>Paradigm milik LightOn menawarkan model fondasi dengan kemampuan yang diklaim melebihi GPT-3. Semua LLM ini dilengkapi dengan API yang memungkinkan developer membuat aplikasi AI generatif yang unik.</li>
            </ul>

        </section>
    </main>
    <main>
        <section id="what-is-ai">
            <h2>Bagaimana cara kerja model bahasa besar ?</h2>
            <p>Faktor kunci dalam cara kerja LLM adalah cara mereka merepresentasikan kata-kata. Bentuk machine learning sebelumnya menggunakan tabel numerik untuk merepresentasikan setiap kata. Namun, bentuk representasi ini tidak dapat mengenali hubungan antara kata-kata, seperti kata-kata dengan makna yang serupa. Keterbatasan ini diatasi dengan menggunakan vektor multidimensi, yang biasa disebut sebagai penyematan kata, untuk merepresentasikan kata-kata sehingga kata-kata dengan makna kontekstual yang sama atau hubungan lainnya saling berdekatan dalam ruang vektor.</p>
            <p>Menggunakan penyematan kata, transformator dapat melakukan praproses teks sebagai representasi numerik melalui dekoder dan memahami konteks kata dan frasa dengan makna yang serupa serta hubungan lain antara kata-kata seperti bagian ucapan. LLM kemudian dapat menerapkan pengetahuan bahasa ini melalui dekoder untuk menghasilkan output yang unik.</p>
        </section>
    </main>
    <main>
        <section id="what-is-ai">
            <h2>Apa saja aplikasi model bahasa besar ?</h2>
            <ul>
                <li>Copywriting
                    <p>Selain GPT-3 dan ChatGPT, tersedia pula Claude, Llama 2, Cohere Command, dan Jurassiccan yang menulis salinan asli. AI21 Wordspice menyarankan perubahan pada kalimat asli untuk meningkatkan gaya dan suara.</p>
                </li>
                <li>Menjawab basis pengetahuan
                    <p>Sering disebut sebagai pemrosesan bahasa alami intensif pengetahuan (KI-NLP), teknik ini mengacu pada LLM yang dapat menjawab pertanyaan spesifik dari bantuan informasi dalam arsip digital. Contohnya adalah kemampuan taman bermain AI21 Studio untuk menjawab pertanyaan pengetahuan umum.</p>
                </li>
                <li>Klasifikasi teks
                    <p>Menggunakan pengelompokan, LLM dapat mengklasifikasikan teks dengan makna atau sentimen yang serupa. Penggunaannya termasuk mengukur sentimen pelanggan, menentukan hubungan antara teks, dan pencarian dokumen.</p>
                </li>
                <li>Pembuatan kode
                    <p>LLM mahir dalam pembuatan kode dari prompt bahasa alami. Amazon Q Developer dapat membuat kode dengan Python, JavaScript, Ruby, dan beberapa bahasa pemrograman lainnya. Aplikasi pengodean lainnya termasuk membuat kueri SQL, menulis perintah shell, dan desain situs web.</p>
                </li>
                <li>Pembuatan teks
                    <p>Mirip dengan pembuatan kode, pembuatan teks dapat melengkapi kalimat yang belum lengkap, menulis dokumentasi produk, atau, seperti Alexa Create, menulis cerita pendek untuk anak-anak.</p>
                </li>
            </ul>
        </section>
    </main>
    <main>
        <section id="what-is-ai">
            <h2>Bagaimana model bahasa besar dilatih ?</h2>
            <p>Jaringan neural berbasis transformator sangat besar. Jaringan ini berisi beberapa simpul dan lapisan. Setiap simpul dalam lapisan memiliki koneksi ke semua simpul di lapisan berikutnya, yang masing-masing memiliki bobot dan bias. Bobot dan bias bersama dengan penyematan dikenal sebagai parameter model. Jaringan neural berbasis transformator yang besar dapat memiliki miliaran parameter. Ukuran model umumnya ditentukan oleh hubungan empiris antara ukuran model, jumlah parameter, dan ukuran data pelatihan.</p>
            <p>Pelatihan dilakukan menggunakan korpus besar data berkualitas tinggi. Selama pelatihan, model secara iteratif menyesuaikan nilai parameter hingga model memprediksi token berikutnya dengan benar dari urutan token input sebelumnya. Pelatihan dilakukan melalui teknik belajar mandiri yang mengajarkan model untuk menyesuaikan parameter guna memaksimalkan kemungkinan token berikutnya dalam contoh pelatihan.</p>
            <p>Setelah dilatih, LLM dapat dengan mudah disesuaikan untuk melakukan banyak tugas menggunakan set data yang diawasi yang relatif kecil, yaitu sebuah proses yang dikenal sebagai fine tuning.</p>
            <h3>Ada 3 Model Pembelajaran Umum</h3>
            <ul>
                <li>Pembelajaran zero-shot; LLM dasar dapat merespons berbagai permintaan tanpa pelatihan eksplisit, seringkali melalui prompt, meski akurasi jawaban bervariasi.</li>
                <li>Pembelajaran few-shot: Dengan memberikan beberapa contoh pelatihan yang relevan, performa model dasar meningkat secara signifikan di area spesifik tersebut.</li>
                <li>Fine-tuning: Ini adalah lanjutan dari pembelajaran few-shot di mana para ilmuwan data melatih model dasar untuk menyesuaikan parameternya dengan data tambahan yang relevan dengan aplikasi spesifik.</li>
            </ul>

        </section>
    </main>
    <main>
        <section id="what-is-ai">
            <h2>Apa masa depan LLM ?</h2>
            <p>Pengenalan model bahasa besar, seperti ChatGPT, Claude 2, dan Llama 2 yang dapat menjawab pertanyaan dan menghasilkan teks menunjukkan kemungkinan-kemungkinan yang menarik pada masa mendatang. Perlahan, tetapi pasti, LLM makin mendekati performa yang setara dengan manusia. Keberhasilan langsung dari LLM ini menunjukkan minat yang besar pada LLM tipe robot yang meniru dan, dalam beberapa konteks, mengungguli otak manusia. Berikut adalah beberapa pemikiran mengenai masa depan LLM,</p>
            <ul>
                <li>Peningkatan kemampuan
                    <p>Meski mengesankan, tingkat teknologi saat ini tidak sempurna dan LLM tidak sepenuhnya sempurna. Namun, rilis yang lebih baru akan meningkatkan akurasi dan kemampuan yang ditingkatkan karena developer belajar cara meningkatkan performa mereka sembari mengurangi bias dan menghilangkan jawaban yang salah.</p>
                </li>
                <li>Pelatihan audiovisual
                    <p>Sementara developer melatih sebagian besar LLM menggunakan teks, beberapa telah memulai model pelatihan menggunakan input video dan audio. Bentuk pelatihan ini harus mengarah pada pengembangan model yang lebih cepat dan membuka kemungkinan baru dalam penggunaan LLM untuk kendaraan otonom.</p>
                </li>
                <li>Transformasi tempat kerja
                    <p>LLM adalah faktor pengganggu yang akan mengubah tempat kerja. LLM kemungkinan akan mengurangi tugas monoton dan berulang dengan cara yang sama seperti yang dilakukan robot untuk tugas-tugas manufaktur berulang. Kemungkinannya mencakup tugas administrasi berulang, chatbot layanan pelanggan, dan copywriting otomatis sederhana.</p>
                </li>
                <li>AI Percakapan
                    <p>LLM tidak diragukan lagi akan meningkatkan performa asisten virtual otomatis, seperti Alexa, Google Assistant, dan Siri. Mereka akan lebih mampu menafsirkan maksud pengguna dan merespons perintah yang canggih.</p>
                </li>
            </ul>
        </section>
    </main>

    <footer>
        <p>&copy; 2024 Website Artificial Intelligence (AI).</p>
    </footer>
</body>
</html>